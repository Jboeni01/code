{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data for usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\justu\\\\Desktop\\\\Masterarbeit\\\\Data\\\\CE'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "# Set directory where files are downloaded to. Chdir has to be changed in order to run on another computer\n",
    "os.chdir('C:\\\\Users\\justu\\\\Desktop\\\\Masterarbeit\\\\Data\\\\CE') \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Download data.\n",
    "Note that the data is compressed as zip files on the website. Download the whole data for the relevant years. This could take a couple of minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0,1,7,8,9]\n",
    "\n",
    "for y_val in y:\n",
    "    urllib.request.urlretrieve(f'https://www.bls.gov/cex/pumd/data/comma/intrvw0{y_val}.zip', f'intrvw0{y_val}.zip') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Generate expenditure data for the given years.\n",
    "2.1: Generate exp data for each year seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Q1 dataset intrvw00/intrvw00/fmli001x.csv loaded; stimulus 2001\n",
      "0 Q2 dataset intrvw00/intrvw00/fmli002.csv loaded; stimulus 2001\n",
      "0 Q3 dataset intrvw00/intrvw00/fmli003.csv loaded; stimulus 2001\n",
      "0 Q4 dataset intrvw00/intrvw00/fmli004.csv loaded; stimulus 2001\n",
      "1 Q1 dataset intrvw01/intrvw01/fmli011x.csv loaded; stimulus 2001\n",
      "1 Q2 dataset intrvw01/intrvw01/fmli012.csv loaded; stimulus 2001\n",
      "1 Q3 dataset intrvw01/intrvw01/fmli013.csv loaded; stimulus 2001\n",
      "1 Q4 dataset intrvw01/intrvw01/fmli014.csv loaded; stimulus 2001\n",
      "7 Q1 dataset intrvw07/fmli071x.csv loaded; stimulus 2008\n",
      "7 Q2 dataset intrvw07/fmli072.csv loaded; stimulus 2008\n",
      "7 Q3 dataset intrvw07/fmli073.csv loaded; stimulus 2008\n",
      "7 Q4 dataset intrvw07/fmli074.csv loaded; stimulus 2008\n",
      "8 Q1 dataset intrvw08/fmli081x.csv loaded; stimulus 2008\n",
      "8 Q2 dataset intrvw08/fmli082.csv loaded; stimulus 2008\n",
      "8 Q3 dataset intrvw08/fmli083.csv loaded; stimulus 2008\n",
      "8 Q4 dataset intrvw08/fmli084.csv loaded; stimulus 2008\n",
      "9 Q1 dataset intrvw09/fmli091x.csv loaded; stimulus 2008\n",
      "9 Q2 dataset intrvw09/fmli092.csv loaded; stimulus 2008\n",
      "9 Q3 dataset intrvw09/fmli093.csv loaded; stimulus 2008\n",
      "9 Q4 dataset intrvw09/fmli094.csv loaded; stimulus 2008\n"
     ]
    }
   ],
   "source": [
    "y = [0,1,7,8,9] # renew years\n",
    "\n",
    "ID = ['NEWID'] #identifier\n",
    "\n",
    "# Expenditure: define the different expenditure types in line with Misra & Surico. \n",
    "# It doesn't matter in which quarter of the year the consumption took place.\n",
    "FD = ['FDHOMECQ', 'FDHOMEPQ', 'FDAWAYCQ', 'FDAWAYPQ', 'ALCBEVCQ', 'ALCBEVPQ' ] # food\n",
    "SND = FD + ['UTILCQ', 'UTILPQ', 'HOUSOPCQ', 'HOUSOPPQ', 'PUBTRACQ', 'PUBTRAPQ', 'GASMOCQ', \n",
    "            'GASMOPQ', 'PERSCACQ', 'PERSCAPQ', 'TOBACCCQ', 'TOBACCPQ', 'MISCCQ', 'MISCPQ'] # strictly non-durables\n",
    "ND = SND + [ 'APPARCQ', 'APPARPQ', 'HEALTHCQ', 'HEALTHPQ', 'READCQ', 'READPQ'] # non-durables\n",
    "DUR = ['EDUCACQ', 'EDUCAPQ', 'HOUSEQCQ', 'HOUSEQPQ', 'SHELTCQ', 'SHELTPQ', 'ENTERTCQ', 'ENTERTPQ',\n",
    "       'CARTKNCQ', 'CARTKNPQ', 'OTHVEHCQ', 'OTHVEHPQ', 'MAINRPCQ', 'MAINRPPQ', 'VEHINSCQ', 'VEHINSPQ', \n",
    "       'VRNTLOCQ', 'VRNTLOPQ', 'VEHFINCQ', 'VEHFINPQ'] # durables\n",
    "\n",
    "TIME = ['QINTRVMO', 'QINTRVYR'] # relevant time variables\n",
    "\n",
    "DEMO = ['AGE_REF', 'FAM_SIZE', 'ST_HOUS', 'MARITAL1', 'AGE2', 'PERSLT18', 'RESPSTAT', 'CUTENURE', 'FINCBTAX', 'EDUC_REF'] # relevant demographics available for all years\n",
    "DEMO2 = ['FSALARYM', 'FINCBTXM'] # relevant demographics available for the second stimulus only\n",
    "\n",
    "ASSETS = ['SAVACCTX','SAVA_CTX','CKBKACTX', 'CKBK_CTX', 'SECESTX', 'SECESTX_' ] # saving accounts; checking accounts, brookerage accounts\n",
    "\n",
    "    # 'RESPSTAT' info on completeness of income information\n",
    "fiscal = dict()\n",
    "\n",
    "for y_val in y:\n",
    "    zf = zipfile.ZipFile(f'{os.getcwd()}/intrvw0{y_val}.zip', 'r')\n",
    "    with zf as zipobj:\n",
    "        df = zipobj.namelist()\n",
    "    fmli = [s for s in df if 'fmli' in s]\n",
    "    zf = zipfile.ZipFile(f'{os.getcwd()}/intrvw0{y_val}.zip', 'r')\n",
    "\n",
    "    for i in range(4):\n",
    "        if (y_val == 0) or (y_val == 1):\n",
    "            fs = pd.read_csv(zf.open(fmli[i]), usecols= ID + FD + ND + DUR + TIME + DEMO + ASSETS, na_values='.')\n",
    "            print(y_val, f'Q{i+1} dataset {fmli[i]} loaded; stimulus 2001')\n",
    "        else:\n",
    "            fs = pd.read_csv(zf.open(fmli[i]), usecols= ID + FD + ND + DUR + TIME + DEMO + DEMO2 + ASSETS, na_values='.') \n",
    "            print(y_val, f'Q{i+1} dataset {fmli[i]} loaded; stimulus 2008')\n",
    "\n",
    "        fs['Year'] = 2000 + y_val\n",
    "        fs['Quarter'] = f'Q{i+1}' # define the quarter to which the data refers to\n",
    "        fs['CustID'] = fs['NEWID'].astype(str).str[:6] # First six digits of NEWID uniquely identify a person, the last digit refers to the interview\n",
    "        fs['CustID'] = fs['CustID'].astype('int64')\n",
    "        fs = fs.set_index(['CustID', 'QINTRVYR', 'QINTRVMO'])\n",
    "        fs['FD'] = fs[FD].sum(axis = 1)\n",
    "        fs['SND'] = fs[SND].sum(axis = 1)\n",
    "        fs['ND'] = fs[ND].sum(axis = 1)\n",
    "        fs['DUR'] = fs[DUR].sum(axis = 1)\n",
    "        fs['TOT'] = fs[['DUR','ND']].sum(axis=1)\n",
    "        fs['valid_finassets'] = 0\n",
    "        fs = fs.sort_index()\n",
    "        fs.loc[fs['SAVA_CTX']=='D', 'valid_finassets'] = 1\n",
    "        fs.loc[fs['CKBK_CTX']=='D', 'valid_finassets'] = 1\n",
    "        fs.loc[fs['SECESTX_']=='D', 'valid_finassets'] = 1\n",
    "        fs['educ_nodegree'] = 0\n",
    "        fs.loc[fs['EDUC_REF']<12,'educ_nodegree'] = 1\n",
    "        fs['educ_highschool'] = 0\n",
    "        fs.loc[fs['EDUC_REF'].isin([12,13,14]),'educ_highschool'] = 1\n",
    "        fs['educ_bachelor'] = 0\n",
    "        fs.loc[fs['EDUC_REF']==15,'educ_bachelor'] = 1\n",
    "        fs['educ_master'] = 0\n",
    "        fs.loc[fs['EDUC_REF']==16,'educ_master'] = 1\n",
    "        fs['educ_doctorate'] = 0\n",
    "        fs.loc[fs['EDUC_REF']==17,'educ_doctorate'] = 1\n",
    "        #fs['ASSETS'] = fs[ASSETS].sum(axis = 1)\n",
    "        fs['finassets'] = fs[ASSETS].sum(axis = 1)\n",
    "        fs.loc[fs['valid_finassets']==0,'finassets'] = np.nan\n",
    "        fiscal[2000 + y_val,i+1] = fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2: Append data for each year and each quarter for the two fiscal stimuli seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs08_raw = fiscal[2007,1]\n",
    "\n",
    "for y in list(range(7,10)):\n",
    "    for q in list(range(1,5)):\n",
    "        if (y == 7) and (q == 1):\n",
    "            pass\n",
    "        elif (y == 9) and (q > 1): #take only the first quarter of 2009\n",
    "            pass\n",
    "        else:\n",
    "            fs08_raw = fs08_raw.append(fiscal[2000 + y,q])\n",
    "\n",
    "fs01_raw = fiscal[2000,1]\n",
    "\n",
    "for y in list(range(2)):\n",
    "    for q in list(range(1,5)):\n",
    "        if (y == 0) and (q == 1):\n",
    "            pass\n",
    "        else:\n",
    "            fs01_raw = fs01_raw.append(fiscal[2000 + y,q])\n",
    "\n",
    "fiscal_stimulus = dict()\n",
    "fiscal_stimulus[1] = fs01_raw\n",
    "fiscal_stimulus[8] = fs08_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDUC_REF</th>\n",
       "      <th>educ_nodegree</th>\n",
       "      <th>educ_highschool</th>\n",
       "      <th>educ_bachelor</th>\n",
       "      <th>educ_master</th>\n",
       "      <th>educ_doctorate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61820.000000</td>\n",
       "      <td>61820.000000</td>\n",
       "      <td>61820.000000</td>\n",
       "      <td>61820.000000</td>\n",
       "      <td>61820.000000</td>\n",
       "      <td>61820.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.181349</td>\n",
       "      <td>0.149401</td>\n",
       "      <td>0.556001</td>\n",
       "      <td>0.188725</td>\n",
       "      <td>0.075736</td>\n",
       "      <td>0.030136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.897697</td>\n",
       "      <td>0.356487</td>\n",
       "      <td>0.496858</td>\n",
       "      <td>0.391293</td>\n",
       "      <td>0.264577</td>\n",
       "      <td>0.170963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           EDUC_REF  educ_nodegree  educ_highschool  educ_bachelor  \\\n",
       "count  61820.000000   61820.000000     61820.000000   61820.000000   \n",
       "mean      13.181349       0.149401         0.556001       0.188725   \n",
       "std        1.897697       0.356487         0.496858       0.391293   \n",
       "min        0.000000       0.000000         0.000000       0.000000   \n",
       "25%       12.000000       0.000000         0.000000       0.000000   \n",
       "50%       13.000000       0.000000         1.000000       0.000000   \n",
       "75%       15.000000       0.000000         1.000000       0.000000   \n",
       "max       17.000000       1.000000         1.000000       1.000000   \n",
       "\n",
       "        educ_master  educ_doctorate  \n",
       "count  61820.000000    61820.000000  \n",
       "mean       0.075736        0.030136  \n",
       "std        0.264577        0.170963  \n",
       "min        0.000000        0.000000  \n",
       "25%        0.000000        0.000000  \n",
       "50%        0.000000        0.000000  \n",
       "75%        0.000000        0.000000  \n",
       "max        1.000000        1.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EDUC = ['EDUC_REF','educ_nodegree','educ_highschool','educ_bachelor','educ_master','educ_doctorate']\n",
    "fs08_raw.loc[:,EDUC].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Generate rebate data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. Fiscal stimulus 2008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEWID       0\n",
      "CUID        0\n",
      "RBTMO       0\n",
      "RBTAMT      0\n",
      "CHCKEFT     0\n",
      "USDINTMO    0\n",
      "USDINTYR    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "REBATE = ['RBTMO', 'RBTAMT', 'CHCKEFT']\n",
    "\n",
    "zf = zipfile.ZipFile(f'{os.getcwd()}/intrvw08.zip', 'r') # rebate data is only in the 2008 folder\n",
    "with zf as zipobj:\n",
    "    df = zipobj.namelist()\n",
    "rbt = [s for s in df if 'rbt08' in s] # relevant file of the previously downloaded data\n",
    "zf = zipfile.ZipFile(f'{os.getcwd()}/intrvw08.zip', 'r')\n",
    "rebate_fs08_raw = pd.read_csv(zf.open(rbt[0]), usecols = REBATE +  ['CUID'] + ['NEWID'] + ['USDINTMO'] + ['USDINTYR'],na_values='.')\n",
    "print(rebate_fs08_raw.isin([0]).sum()) #no zero in data frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.2. Clean rebate data for fs 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of obs. where difference between timing of rebate and interview is either 0 or larger than 3: 775\n",
      "How is diff between interview time and rebate receipt distributed?\n",
      "diff\n",
      "0       94\n",
      "1     1784\n",
      "2     1719\n",
      "3     1631\n",
      "4      667\n",
      "12       2\n",
      "13       9\n",
      "14       3\n",
      "Name: NEWID, dtype: int64\n",
      "no. of obs. where the difference is zero: 94\n",
      "no. of obs. where the difference is zero and it is the last interview: 94\n",
      "no. of obs. where the difference is zero and there is more than one observation per interview: 17\n",
      "no. of obs. where the difference is zero and there is more than one observation per individual: 17\n",
      "no. of obs. where the difference is 4 and it is the first interview: 667\n",
      "no. of obs. where the difference is 4,it is the first interview and there is exactly one entry per individual: 641\n",
      "no. of obs. where the difference is 4, it is the first interview and there is more than one entry per individual: 26\n",
      "unique no. of obs. where the difference is 4, it is the first interview and there is more than one entry per individual: 26\n",
      "The number of individuals who have more than one entry per interview is 220\n",
      "Who has more than 2 entries per interview?\n",
      "          NEWID  RBTAMT\n",
      "CUID                   \n",
      "188789  1887894    1200\n",
      "188789  1887894     600\n",
      "188789  1887894     600\n",
      "190712  1907123     300\n",
      "190712  1907123     600\n",
      "190712  1907123     300\n",
      "['rbtamt_1', 'rbtamt_chk_1', 'rbtamt_e_1', 'rbtmo_1', 'diff_1', 'rbtamt_2', 'rbtamt_chk_2', 'rbtamt_e_2', 'rbtmo_2', 'diff_2']\n"
     ]
    }
   ],
   "source": [
    "#Sum across those individuals who have two entries in the same month. \n",
    "#In order not to lose any information on the way the rebate was received, generate variables that capture the amount received electronically or per mail.\n",
    "\n",
    "rebate_fs08 = rebate_fs08_raw.set_index(['NEWID','CHCKEFT'])\n",
    "rebate_fs08.loc[:,'rbtamt_chk'] = 0\n",
    "rebate_fs08.loc[:,'rbtamt_e'] = 0 # generate new variables that capture the amount received electronically/per mail\n",
    "\n",
    "rebate_fs08.loc[pd.IndexSlice[:,2.0],'rbtamt_e'] = rebate_fs08.loc[pd.IndexSlice[:,2.0],'RBTAMT'] \n",
    "rebate_fs08.loc[pd.IndexSlice[:,1.0],'rbtamt_chk'] = rebate_fs08.loc[pd.IndexSlice[:,1.0],'RBTAMT']\n",
    "\n",
    "rebate_fs08 = rebate_fs08.groupby(['CUID', 'NEWID', 'RBTMO']).agg({  \n",
    "                         #'USDINTMO':['first'], #the first entry is always the same as the last\n",
    "                         #'USDINTYR':['first'], #the first entry is always the same as the last                                         \n",
    "                         'RBTAMT': ['sum'], # sum over entries in the same month, the same interview and the same individual\n",
    "                         'rbtamt_chk': ['sum'],\n",
    "                         'rbtamt_e': ['sum']}) \n",
    "\n",
    "rebate_fs08.columns = rebate_fs08.columns.droplevel(1) #It is not necessary to keep the column labels generated by the groupby command\n",
    "rebate_fs08.loc[(rebate_fs08['rbtamt_chk']==0) & (rebate_fs08['rbtamt_e']==0), ['rbtamt_e','rbtamt_chk']] = np.nan \n",
    "        #entries with no info on how received should be nan\n",
    "\n",
    "\n",
    "\n",
    "rebate_fs08 = pd.merge(rebate_fs08.reset_index(), fs08_raw.reset_index().loc[:,TIME + ['NEWID']] ,on='NEWID', how='inner' ) #merge info on timing of interview\n",
    "rebate_fs08['diff'] = rebate_fs08['QINTRVMO'] - rebate_fs08['RBTMO'] + (rebate_fs08['QINTRVYR'] - 2008)*12 \n",
    "    #difference between interview time and rebate receipt\n",
    "print('no. of obs. where difference between timing of rebate and interview is either 0 or larger than 3:',\n",
    "      rebate_fs08['NEWID'].loc[(rebate_fs08['diff'] == 0 ) | (rebate_fs08['diff']>3)].count())\n",
    "print('How is diff between interview time and rebate receipt distributed?')\n",
    "print(rebate_fs08.groupby('diff')['NEWID'].count()) #In theory the diff should be in range of 1-3\n",
    "\n",
    "\n",
    "##################\n",
    "#when the difference is 0, the reference for the rebate should be changed to the later interview\n",
    "print('no. of obs. where the difference is zero:', rebate_fs08.loc[rebate_fs08['diff']==0, 'CUID'].count()) \n",
    "rebate_fs08['intnr'] = rebate_fs08['NEWID'].astype(str).str[-1:].astype(int) # last number of newid refers to the interview number\n",
    "print('no. of obs. where the difference is zero and it is the last interview:',\n",
    "      rebate_fs08.loc[(rebate_fs08['diff']==0) & (rebate_fs08['intnr']==5), 'CUID'].count())\n",
    "\n",
    "#rebate_fs08 = rebate_fs08.set_index('CUID')\n",
    "\n",
    "RBT = ['RBTAMT', 'rbtamt_chk', 'rbtamt_e']\n",
    "LAGRBT = ['last_' + var for var in RBT]\n",
    "LAGRBT = [item.lower() for item in LAGRBT] #lagged variables\n",
    "FUTRBT = ['fut_' + var for var in RBT]\n",
    "FUTRBT = [item.lower() for item in FUTRBT] #future variables\n",
    "\n",
    "rebate_fs08['int_amount'] =  rebate_fs08.groupby('CUID')['NEWID'].transform('count') #generate sum of entries for given individual\n",
    "\n",
    "for i in range(len(RBT)):\n",
    "    rebate_fs08[LAGRBT[i]] = rebate_fs08.sort_values(by=['NEWID']+TIME).groupby('CUID')[RBT[i]].shift(1) #generate lag\n",
    "    rebate_fs08[FUTRBT[i]] = rebate_fs08.sort_values(by=['NEWID']+TIME).groupby('CUID')[RBT[i]].shift(-1) #generate future\n",
    "    rebate_fs08.loc[(rebate_fs08['int_amount']==1) & (rebate_fs08['diff']==0), FUTRBT[i]] = rebate_fs08.loc[(rebate_fs08['int_amount']==1)\n",
    "                                                                                                            & (rebate_fs08['diff']==0), RBT[i]]\n",
    "                                                                                            \n",
    "rebate_fs08.loc[(rebate_fs08['int_amount']==1) & (rebate_fs08['diff']==0), RBT] = 0 #one entry for person and diff=0: change rebate from now to future\n",
    "\n",
    "print('no. of obs. where the difference is zero and there is more than one observation per interview:',\n",
    "      rebate_fs08.loc[rebate_fs08['NEWID'].isin(rebate_fs08.loc[(rebate_fs08['int_amount']>1) & (rebate_fs08['diff']==0),'NEWID']),\n",
    "                      'NEWID'].count())\n",
    "rebate_fs08 = rebate_fs08.reset_index()\n",
    "print('no. of obs. where the difference is zero and there is more than one observation per individual:',\n",
    "      rebate_fs08.loc[rebate_fs08['CUID'].isin(rebate_fs08.loc[(rebate_fs08['int_amount']>1) & (rebate_fs08['diff']==0),'CUID']),\n",
    "                      'NEWID'].count())\n",
    "    #the no. of obs. is identical between interviews and individuals. Actually, for each individual with int_amount>1 and diff==0 the second \n",
    "    #(and always last) entry is always the one that has a diff of 0. \n",
    "    #Hence, just drop those entries bc the amount is already captured in the future_rbtamt of the entry before\n",
    "rebate_fs08 = rebate_fs08.set_index('CUID')\n",
    "rebate_fs08['dropobs'] = 0 #generate help variable\n",
    "rebate_fs08.loc[rebate_fs08['NEWID'].isin(rebate_fs08.loc[(rebate_fs08['int_amount']>1) & (rebate_fs08['diff']==0),'NEWID']) & \n",
    "                rebate_fs08['fut_rbtamt'].isna(), 'dropobs'] = 1 \n",
    "    #where there are more than one entries for rebates but 1 has a diff = 0; dropobs=1 for diff=0\n",
    "rebate_fs08 = rebate_fs08.loc[rebate_fs08['dropobs']==0] #drop those observations\n",
    "\n",
    "##################\n",
    "#when the difference is 4, the reference for the rebate should be changed to the previous interview\n",
    "print('no. of obs. where the difference is 4 and it is the first interview:', rebate_fs08.loc[(rebate_fs08['diff']==4) & (rebate_fs08['intnr']==2) , 'NEWID'].count())\n",
    "print('no. of obs. where the difference is 4,it is the first interview and there is exactly one entry per individual:',\n",
    "      rebate_fs08.loc[(rebate_fs08['diff']==4) & (rebate_fs08['intnr']==2) & (rebate_fs08['int_amount']==1) , 'NEWID'].count())\n",
    "print('no. of obs. where the difference is 4, it is the first interview and there is more than one entry per individual:',\n",
    "      rebate_fs08.loc[(rebate_fs08['diff']==4) & (rebate_fs08['intnr']==2) & (rebate_fs08['int_amount']>1) , 'NEWID'].count())\n",
    "print('unique no. of obs. where the difference is 4, it is the first interview and there is more than one entry per individual:',\n",
    "      rebate_fs08.loc[(rebate_fs08['diff']==4) & (rebate_fs08['intnr']==2) & (rebate_fs08['int_amount']>1) , 'NEWID'].nunique())\n",
    "#recall that the if the diff is 4 the rebate should be captured as received in the last period. For those individuals where we have more than one entry and the\n",
    "#diff is 4 the lower number entries already capture the last_rbtamt. Hence, we can just delete those entries. \n",
    "rebate_fs08.loc[(rebate_fs08['diff']==4) & (rebate_fs08['intnr']==2) & (rebate_fs08['int_amount']>1), 'dropobs'] = 1\n",
    "rebate_fs08 = rebate_fs08.loc[rebate_fs08['dropobs']==0] #drop those observations\n",
    "\n",
    "rebate_fs08.loc[(rebate_fs08['diff']==4) & (rebate_fs08['intnr']==2) & (rebate_fs08['int_amount']==1), \n",
    "                'last_rbtamt']= rebate_fs08.loc[(rebate_fs08['diff']==4) & (rebate_fs08['intnr']<3), 'RBTAMT']\n",
    "rebate_fs08.loc[(rebate_fs08['diff']==4) & (rebate_fs08['intnr']==2) & (rebate_fs08['int_amount']==1), \n",
    "                'last_rbtamt_e'] = rebate_fs08.loc[(rebate_fs08['diff']==4) & (rebate_fs08['intnr']<3), 'rbtamt_e']\n",
    "rebate_fs08.loc[(rebate_fs08['diff']==4) & (rebate_fs08['intnr']==2) & (rebate_fs08['int_amount']==1), \n",
    "                'last_rbtamt_chk'] = rebate_fs08.loc[(rebate_fs08['diff']==4) & (rebate_fs08['intnr']<3), 'rbtamt_chk']\n",
    "\n",
    "rebate_fs08.loc[(rebate_fs08['diff']==4) & (rebate_fs08['intnr']<3), ['RBTAMT','rbtamt_chk','rbtamt_e']] = 0\n",
    "\n",
    "\n",
    "##################\n",
    "#when the difference is >4, the observations should be dropped\n",
    "rebate_fs08 = rebate_fs08.loc[rebate_fs08['diff']<5].drop(columns=['dropobs','QINTRVMO','QINTRVYR']) #drop any observation where diff==5 or higher\n",
    "rebate_fs08.loc[rebate_fs08['NEWID']==1867435]\n",
    "\n",
    "#################\n",
    "#change to single entry for interview for a given individual\n",
    "rebate_fs08[LAGRBT + FUTRBT] = rebate_fs08[LAGRBT + FUTRBT].fillna(0) #replace all missing values with zero. There are no missing values in the initial data frame\n",
    "\n",
    "rebate_fs08['rbtnr_perint'] = 1\n",
    "rebate_fs08['rbtnr_perint'] = rebate_fs08.groupby('NEWID')['rbtnr_perint'].transform('sum') #count number of entries per interview\n",
    "print('The number of individuals who have more than one entry per interview is',\n",
    "     rebate_fs08.loc[rebate_fs08['rbtnr_perint']>1,'NEWID'].count())\n",
    "print('Who has more than 2 entries per interview?')\n",
    "print(rebate_fs08.loc[rebate_fs08['rbtnr_perint']>2,['NEWID','RBTAMT']])\n",
    "columns = list(rebate_fs08.columns.values)\n",
    "\n",
    "\n",
    "#aggregate over interviewid (interviews)\n",
    "columns =['rbtnr_perint','CUID','RBTMO', 'diff'] + RBT + LAGRBT + FUTRBT  \n",
    "agg = ['first','first'] + [['first','last']]*len(['RBTMO','diff'] + RBT) + ['first'] * len(LAGRBT) + ['last']*len(FUTRBT)  \n",
    "columns_dict = dict(zip(columns, agg))\n",
    "rebate_fs08 = rebate_fs08.reset_index().sort_values(by=['RBTMO']).groupby('NEWID').agg(columns_dict)\n",
    "        #agg: for rbtnr_perint and CUID the first entry; rbtmo and rbt the first and last; lagrbt the first; futrbt the last\n",
    "    \n",
    "#rename columns\n",
    "columns = list(zip(RBT + ['RBTMO','diff'] , ['first']*len(RBT + ['RBTMO','diff']))) + list(zip(RBT + ['RBTMO','diff'], ['last']*len(RBT + ['RBTMO','diff'])))\n",
    "rename = [x + '_1' for x in RBT + ['RBTMO', 'diff']] + [x + '_2' for x in RBT + ['RBTMO', 'diff']]\n",
    "rename = [item.lower() for item in rename]\n",
    "\n",
    "for i in range(len(columns)):\n",
    "    rebate_fs08[rename[i]] = rebate_fs08[columns[i]] #duplicate columns\n",
    "\n",
    "    \n",
    "rebate_fs08 = rebate_fs08.drop(columns=columns)\n",
    "rebate_fs08.columns = rebate_fs08.columns.droplevel(1)\n",
    "rebate_fs08 = rebate_fs08.rename(columns={'RBTAMT':'rbtamt'})\n",
    "\n",
    "print(rename)\n",
    "\n",
    "rename = rename[5:]\n",
    "for i in range(len(rename)):\n",
    "    rebate_fs08.loc[rebate_fs08['rbtnr_perint'] == 1, rename[i]] = 0 #if there's one entry/interview, the rbtamt_2 etc. should be zero\n",
    "    \n",
    "rebate = ['rbtamt', 'rbtamt_chk', 'rbtamt_e']\n",
    "for i in range(len(rebate)):\n",
    "    rebate_fs08[rebate[i]] = rebate_fs08[[rebate[i]+'_1',rebate[i]+'_2']].sum(axis = 1) #sum over rbtamt entries/interview\n",
    "    \n",
    "rebate_fs08.loc[1887894,'rbtamt'] = 2400 #two individuals have three entries/interview. Change manually aggregated rbtamt/interview\n",
    "rebate_fs08.loc[1887894,'rbtamt_chk'] = 2400\n",
    "rebate_fs08.loc[1907123,'rbtamt'] = 1200\n",
    "rebate_fs08.loc[1907123,'rbtamt_chk'] = 300\n",
    "rebate_fs08.loc[1907123,'rbtamt_e'] = 900\n",
    "\n",
    "rebate_fs08.loc[(rebate_fs08['rbtamt_e_1'].isna()) & (rebate_fs08['rbtamt_chk_1'].isna()), ['rbtamt_chk','rbtamt_e']] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 For fiscal stimulus 2001, take data from Johnson, Parker, Souleles. Extracted from https://www.openicpsr.org/openicpsr/project/116245/version/V1/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "JPS = os.getcwd() +'\\\\JPSAERdata.dta'\n",
    "JPS\n",
    "#JPSAERdata\n",
    "rebate_fs01 = pd.read_stata(JPS)\n",
    "rebate_fs01 = rebate_fs01.loc[:,['newid', 'intview', 'yymm', 'taxreb', 'itaxreb', 'ltaxreb', 'iltaxreb', 'l2taxreb', 'il2taxreb', 'itotalreb']] #relevant variables\n",
    "\n",
    "rebate_fs01 = rebate_fs01.rename(columns={'newid': 'CustID'}) #authors' variable newid is custid in all other datasets\n",
    "rebate_fs01['NEWID'] = [str(x) +  str(y) for x, y in zip(rebate_fs01['CustID'], rebate_fs01['intview'])] #generate newid as a combination of custid and the number of the interview\n",
    "rebate_fs01 = rebate_fs01.set_index('NEWID')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: load mortgage data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dataset ['intrvw00/expn00/mor00.csv'] loaded\n",
      "1 dataset ['intrvw01/expn01/mor01.csv'] loaded\n",
      "7 dataset ['expn07/mor07.csv'] loaded\n",
      "8 dataset ['expn08/mor08.csv'] loaded\n",
      "9 dataset ['expn09/mor09.csv'] loaded\n"
     ]
    }
   ],
   "source": [
    "MORTGAGE = ['QESCROWX', 'QBLNCM1X', 'ORGMRTX', 'NEWMRRT', 'QMRTTERM', 'FIXEDRTE', 'OWNYF', 'FRSTPYYR', 'FRSTPYMO'] \n",
    "    #last escrow payment; outstanding principal balance at beginning of month M1; mortage amount; current interest rate;\n",
    "    #term of loan in years; fixed rate mortgage?; property code (100 = home currently lived in); year of first payment; month of first payment\n",
    "    \n",
    "y = [0,1,7,8,9]\n",
    "\n",
    "mortgage = dict()\n",
    "for y_val in y:\n",
    "    zf = zipfile.ZipFile(f'{os.getcwd()}/intrvw0{y_val}.zip', 'r')\n",
    "    with zf as zipobj:\n",
    "        df = zipobj.namelist()\n",
    "    mor = [s for s in df if 'mor' in s]\n",
    "    zf = zipfile.ZipFile(f'{os.getcwd()}/intrvw0{y_val}.zip', 'r')\n",
    "    morg = pd.read_csv(zf.open(mor[0]), usecols= ['NEWID'] + ['QYEAR'] + MORTGAGE, na_values='.' ) # , dtype=types_mortgage\n",
    "    print(y_val, f'dataset {mor} loaded')\n",
    "    morg = morg.loc[morg['QYEAR']< 20011 + y_val*10]\n",
    "    mortgage[2000 + y_val] = morg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "morg08_raw = mortgage[2007]\n",
    "\n",
    "for y in list(range(7,10)):\n",
    "    if (y == 7):\n",
    "        pass\n",
    "    else:\n",
    "        morg08_raw = morg08_raw.append(mortgage[2000 + y])\n",
    "\n",
    "morg01_raw = mortgage[2000]\n",
    "\n",
    "for y in list(range(2)):\n",
    "    if (y == 0):\n",
    "        pass\n",
    "    else:\n",
    "        morg01_raw = morg01_raw.append(mortgage[2000 + y])\n",
    "\n",
    "mortgage_stimulus = dict()\n",
    "\n",
    "mortgage_stimulus[1] = morg01_raw\n",
    "mortgage_stimulus[8] = morg08_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up data and generate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicates in the data frame (year 2001): 29\n",
      "Number of entries where first entry of interview year is not the same as the last: 0\n",
      "Number of entries where first entry of interview month is not the same as the last: 0\n",
      "The number of duplicates in the data frame (year 2008): 42\n",
      "Number of entries where first entry of interview year is not the same as the last: 0\n",
      "Number of entries where first entry of interview month is not the same as the last: 0\n"
     ]
    }
   ],
   "source": [
    "y = [1,8]\n",
    "\n",
    "for y_val in y:\n",
    "    print(f'The number of duplicates in the data frame (year {2000+y_val}):', mortgage_stimulus[y_val].loc[mortgage_stimulus[y_val].duplicated()==True, 'NEWID'].count()) \n",
    "    #For 2008: 42 duplicate obs.; note without controlling for years 6775 obs are duplicates, when only keeping the first entry we still have 6065 duplicates. \n",
    "    #Even though unlikely, it could be that the 42 duplicate entries are actually two seperate mortgages; keep them for now. \n",
    "\n",
    "    mortgage_stimulus[y_val] = pd.merge(mortgage_stimulus[y_val].reset_index() ,fiscal_stimulus[y_val].reset_index().loc[:,TIME + ['NEWID']],on='NEWID', how='inner') \n",
    "        # merge with info on timing of the interview\n",
    "\n",
    "    mortgage_stimulus[y_val]['time'] = ((mortgage_stimulus[y_val]['QINTRVYR'] - mortgage_stimulus[y_val]['FRSTPYYR'])*12 +  \n",
    "                                        mortgage_stimulus[y_val]['QINTRVMO'] - mortgage_stimulus[y_val]['FRSTPYMO'])/12\n",
    "    mortgage_stimulus[y_val]['timeleft'] = mortgage_stimulus[y_val]['QMRTTERM'] - mortgage_stimulus[y_val]['time']\n",
    "    mortgage_stimulus[y_val]['nmorg'] = 1 # generate variable that counts the number of mortgages\n",
    "\n",
    "    #mortgage_stimulus[y_val].reset_index().set_index('NEWID').loc[1993712,:]\n",
    "\n",
    "    #QESCROWX QBLNCM1X ORGMRTX nmort\n",
    "\n",
    "    mortgage_stimulus[y_val] = mortgage_stimulus[y_val].groupby(['NEWID']).agg({  \n",
    "                             'timeleft':['max'], #use info until individual does not have to pay off any debt\n",
    "                             'time':['median'], # take median value of time elapsed since first mortgage payment\n",
    "                             'NEWMRRT':['median'], #take median value of current interest rate \n",
    "                             'nmorg':['sum'], #capture the number of mortgages by individual                                         \n",
    "                             'QINTRVYR': ['first','last'], #keep information on year of interview\n",
    "                             'QINTRVMO': ['first', 'last'], #keep information on month of interview\n",
    "                             'QESCROWX': ['sum'], #sum all amounts of last regular escrow payment\n",
    "                             'QBLNCM1X': ['sum'], #sum all principal balance outstanding at the beginning of month M1\n",
    "                             'ORGMRTX': ['sum'], #sum all amount of mortgage\n",
    "                                }) \n",
    "    mortgage_stimulus[y_val] = mortgage_stimulus[y_val].reset_index()\n",
    "    print('Number of entries where first entry of interview year is not the same as the last:',\n",
    "          mortgage_stimulus[y_val].loc[(mortgage_stimulus[y_val]['QINTRVYR','first']!=mortgage_stimulus[y_val]['QINTRVYR','last']), 'NEWID'].count())\n",
    "    \n",
    "    print('Number of entries where first entry of interview month is not the same as the last:',\n",
    "          mortgage_stimulus[y_val].loc[(mortgage_stimulus[y_val]['QINTRVMO','first']!=mortgage_stimulus[y_val]['QINTRVMO','last']), 'NEWID'].count())\n",
    "    \n",
    "    mortgage_stimulus[y_val] = mortgage_stimulus[y_val].set_index('NEWID')\n",
    "    mortgage_stimulus[y_val] = mortgage_stimulus[y_val].drop(columns=[['QINTRVYR','first'],['QINTRVYR','last'],['QINTRVMO','first'],['QINTRVMO','last']])\n",
    "\n",
    "    mortgage_stimulus[y_val].columns = mortgage_stimulus[y_val].columns.droplevel(1) # drop column labels generated by the groupby command\n",
    "    mortgage_stimulus[y_val] = mortgage_stimulus[y_val].rename(columns={'QESCROWX': 'qescrowx_sum', 'QBLNCM1X': 'qblncm1x_sum', 'ORGMRTX': 'orgmrtx_sum', 'NEWMRRT': 'newmrrt_median'})\n",
    "    mortgage_stimulus[y_val]['morgpayment'] = mortgage_stimulus[y_val]['qblncm1x_sum']*mortgage_stimulus[y_val]['newmrrt_median']/ mortgage_stimulus[y_val]['timeleft'] /12\n",
    "        #morgage payment per month: sum of outstanding balance times median interest rate on morgage divided by max time left on morgage times 12\n",
    "    mortgage_stimulus[y_val].loc[mortgage_stimulus[y_val]['timeleft']==0, 'morgpayment'] = mortgage_stimulus[y_val]['qblncm1x_sum']*mortgage_stimulus[y_val]['newmrrt_median']\n",
    "morg01_raw = mortgage_stimulus[1]\n",
    "morg08_raw = mortgage_stimulus[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Merge the data sets 2008**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs08 = pd.merge(fs08_raw.reset_index(), rebate_fs08.reset_index(), how = 'left', on = 'NEWID') #.set_index([ 'CustID','QINTRVYR', 'QINTRVMO']).sort_index()\n",
    "\n",
    "\n",
    "fs08 = fs08.reset_index().set_index(['CustID']) #.drop(columns='CUID')\n",
    "\n",
    "#keep only observations for individuals who were questioned at least once between 6,2008 and 3,2009\n",
    "fs08['intrvyr_max'] =  fs08.groupby('CustID')['QINTRVYR'].transform('last')\n",
    "fs08['intrvmo_max'] =  fs08.groupby('CustID')['QINTRVMO'].transform('last')\n",
    "\n",
    "fs08['keepcons'] = 0\n",
    "\n",
    "fs08.loc[(fs08['intrvyr_max']==2008) & (fs08['intrvmo_max']>=6),['keepcons']] = 1 \n",
    "#fs08.loc[(fs08['QINTRVYR']==2009) & (fs08['QINTRVMO']<=3),['keepcons']] = 1\n",
    "fs08.loc[(fs08['intrvyr_max']==2009) & (fs08['intrvmo_max']<=3),['keepcons']] = 1 \n",
    "fs08 = fs08.loc[fs08['keepcons']==1]\n",
    "\n",
    "fs08.dtypes #check datatypes of variables in the data frame\n",
    "fs08['age'] = (fs08['AGE2'] + fs08['AGE_REF'])/2 #where we have information about husband and spouse age is a combination of both\n",
    "fs08.loc[fs08['age'].isna(), 'age'] = fs08.loc[fs08['age'].isna(), 'AGE_REF'] #where no info about partner's age, age is just ref person's age\n",
    "fs08['adults'] = fs08['FAM_SIZE'] - fs08['PERSLT18'] #number of adults\n",
    "fs08['timetrend'] = (fs08['QINTRVYR'] - 2008)*12 + fs08['QINTRVMO']\n",
    "fs08['int_entries'] = 1\n",
    "fs08['int_entries'] = fs08.groupby('NEWID')['int_entries'].transform('sum')\n",
    "\n",
    "#There are some variables for which lagged values are required\n",
    "LAGVAR = ['age', 'PERSLT18', 'adults', 'timetrend', 'FD', 'SND', 'ND', 'DUR','TOT']\n",
    "LAGNAMES = ['last_' + var for var in LAGVAR]\n",
    "CHGNAMES = ['chg_' + var for var in LAGVAR]\n",
    "FUTCONS = ['fut_' + c for c in LAGVAR[4:]]\n",
    "\n",
    "#Augment lagged and future values of rebate\n",
    "RBT = ['rbtamt', 'rbtamt_chk', 'rbtamt_e']\n",
    "LAGRBT = ['last_' + var for var in RBT] #lagged variables\n",
    "FUTRBT = ['fut_' + var for var in RBT] #future variables\n",
    "\n",
    "for i in range(len(RBT)):\n",
    "    fs08.loc[fs08[RBT[i]]==0, RBT[i]] = np.nan #change from zero to Nan (as previously checked there are no zeros in the original data)\n",
    "    fs08.loc[fs08[LAGRBT[i]]==0, LAGRBT[i]] = np.nan\n",
    "    fs08.loc[fs08[FUTRBT[i]]==0, FUTRBT[i]] = np.nan\n",
    "    #just one entry left per interview, aggregate over custid to add lag/future value of rebate if it's zero:\n",
    "    fs08.loc[(fs08[LAGRBT[i]]==0) | (fs08[LAGRBT[i]].isna()),\n",
    "             LAGRBT[i]] =  fs08.loc[(fs08[LAGRBT[i]]==0) | (fs08[LAGRBT[i]].isna())].groupby('CustID')[RBT[i]].shift(1) \n",
    "    fs08.loc[(fs08[FUTRBT[i]]==0) | (fs08[FUTRBT[i]].isna()),\n",
    "             FUTRBT[i]] =  fs08.loc[(fs08[FUTRBT[i]]==0) | (fs08[FUTRBT[i]].isna())].groupby('CustID')[RBT[i]].shift(-1) \n",
    "    \n",
    " \n",
    "fs08 = fs08.reset_index()\n",
    "\n",
    "for i in range(len(FUTCONS)):\n",
    "    fs08[FUTCONS[i]] = fs08.sort_values(by = ['NEWID']).groupby('CustID')[LAGVAR[4:][i]].shift(-1)\n",
    "\n",
    "\n",
    "for i in range(len(LAGVAR)):\n",
    "    fs08[LAGNAMES[i]] = fs08.sort_values(by = ['NEWID']).groupby('CustID')[LAGVAR[i]].shift(1)\n",
    "    fs08[CHGNAMES[i]] = fs08[LAGVAR[i]] - fs08[LAGNAMES[i]]\n",
    "    if LAGVAR[i] == 'age':\n",
    "        fs08.loc[abs(fs08[CHGNAMES[i]])>1, 'keepcons'] = 0 #age of reference person shouldn't change by more than 1 between the interviews\n",
    "    elif LAGVAR[i] == 'timetrend':\n",
    "        fs08.loc[abs(fs08[CHGNAMES[i]]>3), 'keepcons'] = 0 #time between interviews shouldn't be larger than 1\n",
    "        fs08.loc[(fs08[CHGNAMES[i]]==0) & (fs08['int_entries']<2), 'keepcons'] = 0 \n",
    "        #the time between two interviews shouldn't be zero, if there are two entries per interview the lag will be zero; make sure to not drop  \n",
    "    elif (LAGVAR[i] == 'PERSLT18') | (LAGVAR[i] == 'adults') :\n",
    "        fs08.loc[abs(fs08[CHGNAMES[i]])>3, 'keepcons'] = 0 #change in number of adults or individuals below 18 shouldn't change by more than 3\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "#fs08['keepcons'] = fs08.groupby('CustID')['keepcons'].transform('min')\n",
    "fs08 = fs08.loc[fs08['keepcons']==1] #clean data\n",
    "fs08 = fs08.drop(columns = LAGNAMES[0:3] + CHGNAMES[0:3] + ['keepcons', 'index'])\n",
    "\n",
    "\n",
    "fs08 = fs08.loc[fs08['age'].between(21,85)] #drop very old and very young households\n",
    "\n",
    "fs08 = fs08.loc[fs08['ST_HOUS'] != 1] #drop households with student housing\n",
    "fs08['totalint'] =  fs08.groupby('CustID')['QINTRVMO'].transform('count')\n",
    "fs08 = fs08.loc[fs08['totalint']>1] #drop households with only one interview entry\n",
    "\n",
    "#merge with mortgage data\n",
    "fs08 = pd.merge(fs08.reset_index(), morg08_raw.reset_index(), how = 'left', on = 'NEWID').sort_values(by = ['NEWID']).set_index('CustID') #27330 obs\n",
    "fs08 = fs08.drop(columns = 'index')\n",
    "\n",
    "\n",
    "##drop first interview\n",
    "#fs08['drop_first'] = 1\n",
    "#fs08['drop_first'] = fs08.sort_values(by=['NEWID']).groupby('CustID')['drop_first'].transform('cumsum')\n",
    "#for i in range(len(CHGNAMES[4:])):\n",
    "#    fs08.loc[(fs08['drop_first']==1)&(fs08[CHGNAMES[4:][i]].notna()),'drop_first']=2\n",
    "#\n",
    "#   \n",
    "#fs08 = fs08.loc[fs08['drop_first']>1].drop(columns='drop_first')\n",
    "\n",
    "fs08.to_csv( os.getcwd() + '\\\\fs08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustID\n",
       "183843     717.9999\n",
       "183843     195.0000\n",
       "183843     807.0000\n",
       "183843          NaN\n",
       "183849    2209.9998\n",
       "183849    2244.9998\n",
       "183849    1869.0000\n",
       "183849          NaN\n",
       "183850    2990.0001\n",
       "183850    2469.9999\n",
       "183850    3615.0000\n",
       "183850          NaN\n",
       "183853    1415.0002\n",
       "183853    1517.0001\n",
       "183853    1460.0000\n",
       "183853          NaN\n",
       "183858    2435.0001\n",
       "183858    2713.9998\n",
       "183858    3384.0001\n",
       "183858          NaN\n",
       "183864     975.0000\n",
       "183864    3249.9999\n",
       "183864    1755.0000\n",
       "183864          NaN\n",
       "183869    3507.0000\n",
       "183869          NaN\n",
       "183872    2250.0000\n",
       "183872    1690.0002\n",
       "183872    2340.0000\n",
       "183872          NaN\n",
       "            ...    \n",
       "197310    1164.9999\n",
       "197310          NaN\n",
       "197311    3159.9999\n",
       "197311          NaN\n",
       "197312     780.0000\n",
       "197312          NaN\n",
       "197313    4096.9999\n",
       "197313          NaN\n",
       "197314     714.9999\n",
       "197314          NaN\n",
       "197315    1618.9999\n",
       "197315          NaN\n",
       "197316    1170.0000\n",
       "197316          NaN\n",
       "197317    1690.0002\n",
       "197317          NaN\n",
       "197318     519.9999\n",
       "197318          NaN\n",
       "197319     780.0000\n",
       "197319          NaN\n",
       "197320    1120.0002\n",
       "197320          NaN\n",
       "197321     884.0001\n",
       "197321          NaN\n",
       "197325     650.0001\n",
       "197325          NaN\n",
       "197326    2794.9998\n",
       "197326          NaN\n",
       "197327    1040.0001\n",
       "197327          NaN\n",
       "Name: fut_FD, Length: 25989, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs08.loc[:,'fut_FD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
